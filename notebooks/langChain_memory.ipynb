{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "_ = load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance of chat to make prompts\n",
    "chat = ChatOpenAI(\n",
    "    api_key = os.getenv(\"OPEN_AI_KEY\"),\n",
    "    model=os.getenv(\"LLM_MODEL\")\n",
    ")\n",
    "\n",
    "# create a memory instance\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# create the converstation with memory and chat\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, I'm Cristhian\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Cristhian! How can I assist you today?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, I'm Cristhian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, I'm Cristhian\n",
      "AI: Hello Cristhian! How can I assist you today?\n",
      "Human: What is 1 + 1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1 + 1 is equal to 2.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1 + 1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, I'm Cristhian\n",
      "AI: Hello Cristhian! How can I assist you today?\n",
      "Human: What is 1 + 1?\n",
      "AI: 1 + 1 is equal to 2.\n",
      "Human: what is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Cristhian.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"what is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the memory buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, I'm Cristhian\n",
      "AI: Hello Cristhian! How can I assist you today?\n",
      "Human: What is 1 + 1?\n",
      "AI: 1 + 1 is equal to 2.\n",
      "Human: what is my name?\n",
      "AI: Your name is Cristhian.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: hi\n",
      "AI: hello, how are you\n",
      "Human: how is it going?\n",
      "AI: not so much, how about you?\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferWindowMemory(k=2)\n",
    "memory.save_context({'input':'hi'},{'output':'hello, how are you'})\n",
    "memory.save_context({'input':'how is it going?'},{'output':'not so much, how about you?'})\n",
    "\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: I'm really great , actually\n",
      "AI: why's that?\n",
      "Human: I'm learning new LLMs things , actually\n",
      "AI: that's awesome!\n"
     ]
    }
   ],
   "source": [
    "memory.save_context({'input':\"I'm really great , actually\"},{'output':\"why's that?\"})\n",
    "memory.save_context({'input':\"I'm learning new LLMs things , actually\"},{'output':\"that's awesome!\"})\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Buffered Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key = os.getenv(\"OPEN_AI_KEY\"),\n",
    "    model=os.getenv(\"LLM_MODEL\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: hi\n",
      "AI: hello, how are you\n",
      "Human: how is it going?\n",
      "AI: not so much, how about you?\n",
      "Human: I'm really great , actually\n",
      "AI: why's that?\n",
      "Human: I'm learning new LLMs things , actually\n",
      "AI: that's awesome!\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationTokenBufferMemory(max_token_limit=100, llm=llm)\n",
    "memory.save_context({'input':'hi'},{'output':'hello, how are you'})\n",
    "memory.save_context({'input':'how is it going?'},{'output':'not so much, how about you?'})\n",
    "memory.save_context({'input':\"I'm really great , actually\"},{'output':\"why's that?\"})\n",
    "memory.save_context({'input':\"I'm learning new LLMs things , actually\"},{'output':\"that's awesome!\"})\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: not so much, how about you?\n",
      "Human: I'm really great , actually\n",
      "AI: why's that?\n",
      "Human: I'm learning new LLMs things , actually\n",
      "AI: that's awesome!\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationTokenBufferMemory(max_token_limit=60, llm=llm)\n",
    "memory.save_context({'input':'hi'},{'output':'hello, how are you'})\n",
    "memory.save_context({'input':'how is it going?'},{'output':'not so much, how about you?'})\n",
    "memory.save_context({'input':\"I'm really great , actually\"},{'output':\"why's that?\"})\n",
    "memory.save_context({'input':\"I'm learning new LLMs things , actually\"},{'output':\"that's awesome!\"})\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key = os.getenv(\"OPEN_AI_KEY\"),\n",
    "    model=os.getenv(\"LLM_MODEL\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: The human greets the AI and the AI responds by asking how the human is feeling. The human says they are feeling great because they are learning new things about LLMs. The AI thinks that's awesome and suggests doing a podcast episode about LLMs. The human agrees and suggests discussing the history of NLP for sentiment analysis and how it has evolved into the large language models like ChatGPT and Bard. The AI agrees and emphasizes the importance of understanding the technology behind these models.\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationSummaryBufferMemory(max_token_limit=70, llm=llm)\n",
    "\n",
    "basic_ideas_llm = \"\"\" some of the basic ideas may related with the history of NLP for sentiment analysis \\\n",
    "and how everithing turned into that large language models that we see everywhere now, like ChatGPT and Bard \\\n",
    "People use to make use of them but they dont know everithing that goes behind the courtain, not only about the processing \\\n",
    "but also about the capacity and the technological stach needed for this, what do you thing?\n",
    "\"\"\"\n",
    "\n",
    "memory.save_context({'input':'hi'},{'output':'hello, how are you'})\n",
    "memory.save_context({'input':'how is it going?'},{'output':'not so much, how about you?'})\n",
    "memory.save_context({'input':\"I'm really great , actually\"},{'output':\"why's that?\"})\n",
    "memory.save_context({'input':\"I'm learning new LLMs things , actually\"},{'output':\"that's awesome!\"})\n",
    "memory.save_context({'input':\"what do you thing about doing a podcast episode talking about LLMs\"},{'output':f\"that soulds great!,{basic_ideas_llm}\"})\n",
    "print(memory.load_memory_variables({})[\"history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human greets the AI and the AI responds by asking how the human is feeling. The human says they are feeling great because they are learning new things about LLMs. The AI thinks that's awesome and suggests doing a podcast episode about LLMs. The human agrees and suggests discussing the history of NLP for sentiment analysis and how it has evolved into the large language models like ChatGPT and Bard. The AI agrees and emphasizes the importance of understanding the technology behind these models.\n",
      "Human: yes totally, i agree with all what you say, in simple words, what would we require to record the podcast?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To record a podcast, you would need a few essential items and a recording setup. Here\\'s a simplified list of what you would require:\\n\\n1. Microphones: Good quality microphones are crucial for capturing clear and professional-sounding audio. Depending on the number of participants, you may need multiple microphones.\\n\\n2. Headphones: Each participant should have a pair of headphones to monitor their audio and ensure there are no technical issues during recording.\\n\\n3. Audio Interface: An audio interface acts as the bridge between your microphones and your computer. It converts the analog audio signal into a digital format that can be recorded on your computer.\\n\\n4. Recording Software: There are various recording software options available, such as Audacity, GarageBand, or Adobe Audition. These programs allow you to capture and edit your audio.\\n\\n5. Pop Filters and Shock Mounts: Pop filters help reduce plosive sounds (such as \"p\" and \"b\" sounds) and protect the microphones. Shock mounts prevent vibrations and handling noise from reaching the microphones.\\n\\n6. Room Acoustics: It\\'s important to record in a quiet environment with minimal background noise. Consider using soundproofing panels or foam to improve the acoustic quality of the room.\\n\\n7. Script or Outline: Prepare a script or outline for your podcast episode to ensure a smooth flow of conversation and to cover all the points you want to discuss.\\n\\nRemember, these are just the basics, and you can always upgrade or add more equipment based on your specific needs and budget.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"yes totally, i agree with all what you say, in simple words, what would we require to record the podcast?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To record a podcast, you would need a few essential items and a recording setup. Here's a simplified list of what you would require:\n",
      "\n",
      "1. Microphones: Good quality microphones are crucial for capturing clear and professional-sounding audio. Depending on the number of participants, you may need multiple microphones.\n",
      "\n",
      "2. Headphones: Each participant should have a pair of headphones to monitor their audio and ensure there are no technical issues during recording.\n",
      "\n",
      "3. Audio Interface: An audio interface acts as the bridge between your microphones and your computer. It converts the analog audio signal into a digital format that can be recorded on your computer.\n",
      "\n",
      "4. Recording Software: There are various recording software options available, such as Audacity, GarageBand, or Adobe Audition. These programs allow you to capture and edit your audio.\n",
      "\n",
      "5. Pop Filters and Shock Mounts: Pop filters help reduce plosive sounds (such as \"p\" and \"b\" sounds) and protect the microphones. Shock mounts prevent vibrations and handling noise from reaching the microphones.\n",
      "\n",
      "6. Room Acoustics: It's important to record in a quiet environment with minimal background noise. Consider using soundproofing panels or foam to improve the acoustic quality of the room.\n",
      "\n",
      "7. Script or Outline: Prepare a script or outline for your podcast episode to ensure a smooth flow of conversation and to cover all the points you want to discuss.\n",
      "\n",
      "Remember, these are just the basics, and you can always upgrade or add more equipment based on your specific needs and budget.\n"
     ]
    }
   ],
   "source": [
    "print('To record a podcast, you would need a few essential items and a recording setup. Here\\'s a simplified list of what you would require:\\n\\n1. Microphones: Good quality microphones are crucial for capturing clear and professional-sounding audio. Depending on the number of participants, you may need multiple microphones.\\n\\n2. Headphones: Each participant should have a pair of headphones to monitor their audio and ensure there are no technical issues during recording.\\n\\n3. Audio Interface: An audio interface acts as the bridge between your microphones and your computer. It converts the analog audio signal into a digital format that can be recorded on your computer.\\n\\n4. Recording Software: There are various recording software options available, such as Audacity, GarageBand, or Adobe Audition. These programs allow you to capture and edit your audio.\\n\\n5. Pop Filters and Shock Mounts: Pop filters help reduce plosive sounds (such as \"p\" and \"b\" sounds) and protect the microphones. Shock mounts prevent vibrations and handling noise from reaching the microphones.\\n\\n6. Room Acoustics: It\\'s important to record in a quiet environment with minimal background noise. Consider using soundproofing panels or foam to improve the acoustic quality of the room.\\n\\n7. Script or Outline: Prepare a script or outline for your podcast episode to ensure a smooth flow of conversation and to cover all the points you want to discuss.\\n\\nRemember, these are just the basics, and you can always upgrade or add more equipment based on your specific needs and budget.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
